{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "from random import randint\n",
    "\n",
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors(dataset_type):\n",
    "    \n",
    "    #set parameters for training and testing\n",
    "    if (dataset_type == \"train\"):\n",
    "        directory = os.path.join(os.getcwd(), 'data_thuyg20_sre/enroll')\n",
    "        no_of_frames = 400\n",
    "    elif (dataset_type == \"test\"):    \n",
    "        directory = os.path.join(os.getcwd(), 'data_thuyg20_sre/test')\n",
    "        no_of_frames = 40\n",
    "    \n",
    "    dataset = numpy.empty([0, 40])\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        # filter speakers\n",
    "        names = ['F101', 'F102', 'F103', 'F104', 'F105', 'M101', 'M102', 'M103', 'M104']\n",
    "\n",
    "        if any(name in file for name in names):\n",
    "            \n",
    "            # extract mfcc vectors\n",
    "            (rate,sig) = wav.read(os.path.join(directory, file))\n",
    "            mfcc_feat = mfcc(sig,rate)\n",
    "            d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "            dd_mfcc_feat = delta(d_mfcc_feat, 2)\n",
    "            \n",
    "            #fbank_feat = logfbank(sig,rate)\n",
    "            mfcc_vectors = mfcc_feat[11:11+no_of_frames,:]\n",
    "            dmfcc_vectors = d_mfcc_feat[11:11+no_of_frames,:]\n",
    "            ddmfcc_vectors = dd_mfcc_feat[11:11+no_of_frames,:]\n",
    "            \n",
    "            feature_vectors = numpy.hstack((mfcc_vectors, dmfcc_vectors, ddmfcc_vectors))\n",
    "            #print(feature_vectors.shape)\n",
    "            \n",
    "            # get speaker index from filename\n",
    "            speaker_index = file.split(\"_\")[0]\n",
    "            if speaker_index[0] == 'M':\n",
    "                speaker_index = 5 + int(speaker_index[3:])\n",
    "            else:\n",
    "                speaker_index = int(speaker_index[3:])\n",
    "\n",
    "            #append speaker index to feature vectors\n",
    "            np_speaker_index = numpy.array([speaker_index])\n",
    "            temp = numpy.tile(np_speaker_index[numpy.newaxis,:], (feature_vectors.shape[0],1))\n",
    "            concatenated_feature_vector = numpy.concatenate((feature_vectors,temp), axis=1)\n",
    "            \n",
    "            #print(dataset.shape)\n",
    "            #print(concatenated_feature_vector.shape)\n",
    "            # append file's data to dataset\n",
    "            dataset = numpy.concatenate((dataset, concatenated_feature_vector), axis=0)\n",
    "            \n",
    "            \n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import genfromtxt\n",
    "my_data = get_feature_vectors(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 40)\n"
     ]
    }
   ],
   "source": [
    "# print(my_data)\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = numpy.copy(my_data[:, 39:])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 39)\n",
      "(1, 39)\n",
      "(1, 39)\n",
      "(3600, 39)\n"
     ]
    }
   ],
   "source": [
    "X = numpy.copy(my_data[:, :39])\n",
    "print(X.shape)\n",
    "mean = X.mean(0, keepdims=True)\n",
    "\n",
    "print(mean.shape)\n",
    "std_deviation = numpy.std(X, axis=0, keepdims=True)\n",
    "print(std_deviation.shape)\n",
    "\n",
    "normalized_X = (X - mean) / std_deviation\n",
    "print(normalized_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 40)\n",
      "(3600, 39)\n",
      "(3600, 39)\n",
      "(3600, 1)\n"
     ]
    }
   ],
   "source": [
    "test_model = get_feature_vectors(\"test\")\n",
    "print(test_model.shape)\n",
    "\n",
    "test_X = numpy.copy(test_model[:, :39])\n",
    "print(test_X.shape)\n",
    "\n",
    "normalized_test_X = (test_X - mean) / std_deviation\n",
    "print(normalized_test_X.shape)\n",
    "\n",
    "test_Y = numpy.copy(test_model[:, 39:])\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neupy import algorithms, environment\n",
    "from sklearn import metrics\n",
    "#from sklearn import datasets\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.reproducible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.load_digits()\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     dataset.data, dataset.target, test_size=0.3\n",
    "# )\n",
    "\n",
    "Y = Y.flatten()\n",
    "test_Y = test_Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn = algorithms.PNN(std=6, verbose=False)\n",
    "pnn.train(normalized_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "y_predicted = pnn.predict(normalized_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. ... 9. 9. 9.]\n",
      "[5. 5. 5. ... 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "print(test_Y)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26805555555555555"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_Y, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
