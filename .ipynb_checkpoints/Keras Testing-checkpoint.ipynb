{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('mfcc_vectors.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 21)\n"
     ]
    }
   ],
   "source": [
    "# print(my_data)\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = numpy.copy(my_data[:, 20:])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 12)\n",
      "(1, 12)\n",
      "(1, 12)\n",
      "(2000, 12)\n"
     ]
    }
   ],
   "source": [
    "X = numpy.copy(my_data[:, :12])\n",
    "print(X.shape)\n",
    "mean = X.mean(0, keepdims=True)\n",
    "\n",
    "print(mean.shape)\n",
    "std_deviation = numpy.std(X, axis=0, keepdims=True)\n",
    "print(std_deviation.shape)\n",
    "\n",
    "normalized_X = (X - mean) / std_deviation\n",
    "print(normalized_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras import utils as np_utils\n",
    "\n",
    "one_hot_labels = np_utils.to_categorical(Y, num_classes=6)\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 1.6928 - acc: 0.1935\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 1.5421 - acc: 0.2845\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 1.4868 - acc: 0.3315\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 1.4266 - acc: 0.3515\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 1.3747 - acc: 0.3815\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 1.3391 - acc: 0.3835\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 1.3094 - acc: 0.4120\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 1.2831 - acc: 0.4190\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 1.2556 - acc: 0.4425\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 1.2368 - acc: 0.4580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c66579860>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=12))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(normalized_X, one_hot_labels, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "# MultiLayer Perceptron\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(32, activation='relu', input_dim=12))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(normalized_X, one_hot_labels, epochs=10, batch_size=32)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 21)\n",
      "(2200, 12)\n",
      "(2200, 12)\n",
      "(2200, 1)\n"
     ]
    }
   ],
   "source": [
    "test_model = genfromtxt('test_vectors.csv', delimiter=',')\n",
    "print(test_model.shape)\n",
    "\n",
    "test_X = numpy.copy(test_model[:, :12])\n",
    "print(test_X.shape)\n",
    "\n",
    "normalized_test_X = (test_X - mean) / std_deviation\n",
    "print(normalized_test_X.shape)\n",
    "\n",
    "test_Y = numpy.copy(test_model[:, 20:])\n",
    "print(test_Y.shape)\n",
    "test_labels = np_utils.to_categorical(test_Y, num_classes=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(4.3494133949279785, dtype=float32), array(0.46409091353416443, dtype=float32)]\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(model.test_on_batch(test_X, test_labels, sample_weight=None))\n",
    "print(model.metrics_names)\n",
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 1, 3, 3, 1, 4, 4, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 4, 1, 3, 4, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "[ 2.  1.  4.  1.  4.  1.  5.  5.  1.  1.  3.  3.  5.  3.  5.  2.  4.  5.\n",
      "  2.  4.  3.  1.  1.  4.  1.  5.  1.  4.  4.  1.  1.  5.  3.  1.  1.  3.\n",
      "  5.  5.  4.  4.  1.  5.  4.  1.  3.  3.  2.  3.  3.  1.  1.  5.  3.  3.\n",
      "  5.]\n",
      "55\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "b = [sum(predictions[current: current+40]) for current in range(0, len(predictions), 40)]\n",
    "predicted_Y = []\n",
    "for row in b:\n",
    "    predicted_Y.append(row.argmax(axis=0))\n",
    "    \n",
    "print(predicted_Y)\n",
    "print(test_Y[::40].T[0])\n",
    "\n",
    "diff = predicted_Y - test_Y[::40].T[0]\n",
    "\n",
    "print(len(predicted_Y))\n",
    "print(sum(x == 0 for x in diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
