{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "from random import randint\n",
    "# import librosa\n",
    "\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# every frame is considered independent\n",
    "\n",
    "no_of_features = 13\n",
    "no_of_fbank_features = 13\n",
    "no_of_columns = (3 * no_of_features) + no_of_fbank_features\n",
    "\n",
    "def get_feature_vectors(dataset_type):\n",
    "    \n",
    "    #set parameters for training and testing\n",
    "    if (dataset_type == \"train\"):\n",
    "        directory = os.path.join(os.getcwd(), 'voices_processed/enroll')\n",
    "        no_of_frames = 400\n",
    "        start_frame = 1\n",
    "    elif (dataset_type == \"test\"):    \n",
    "        directory = os.path.join(os.getcwd(), 'voices_processed/test')\n",
    "        no_of_frames = 40\n",
    "        start_frame = 1\n",
    "        \n",
    "    dataset = numpy.empty([0, no_of_columns + 1])\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        # filter speakers\n",
    "        names = ['F001', 'F002', 'F003', 'F004', 'M001', 'M002', 'M003', 'M004']\n",
    "\n",
    "        if any(name in file for name in names):\n",
    "            \n",
    "            # extract mfcc vectors\n",
    "            (rate,sig) = wav.read(os.path.join(directory, file))\n",
    "            fbank_feat = logfbank(sig,rate)\n",
    "            mfcc_feat = mfcc(sig,rate,winlen=0.032,winstep=0.016,numcep=13,nfft=2048)\n",
    "#             print(\"Rate :\" + str(rate) + \" \" + file)\n",
    "#             print(\"Signal :\" + str(sig) + \" \" + file)\n",
    "#             y, sr = librosa.load(os.path.join(directory, file))\n",
    "#             mfcc_feat = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=2048).T\n",
    "            d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "            dd_mfcc_feat = delta(d_mfcc_feat, 2)\n",
    "            \n",
    "#             fbank_feat = logfbank(sig,rate)\n",
    "            mfcc_vectors = mfcc_feat[start_frame:start_frame+no_of_frames,:no_of_features]\n",
    "            dmfcc_vectors = d_mfcc_feat[start_frame:start_frame+no_of_frames,:no_of_features]\n",
    "            ddmfcc_vectors = dd_mfcc_feat[start_frame:start_frame+no_of_frames,:no_of_features]\n",
    "            fbank_vectors = fbank_feat[start_frame:start_frame+no_of_frames,:no_of_fbank_features]\n",
    "            \n",
    "            feature_vectors = numpy.hstack((mfcc_vectors, dmfcc_vectors, ddmfcc_vectors, fbank_vectors))\n",
    "#             print(feature_vectors.shape)\n",
    "            \n",
    "            # get speaker index from filename\n",
    "            speaker_index = file.split(\"_\")[0]\n",
    "            if speaker_index[0] == 'M':\n",
    "                speaker_index = 5 + int(speaker_index[3:])\n",
    "            else:\n",
    "                speaker_index = int(speaker_index[3:])\n",
    "\n",
    "            #append speaker index to feature vectors\n",
    "            np_speaker_index = numpy.array([speaker_index])\n",
    "            temp = numpy.tile(np_speaker_index[numpy.newaxis,:], (feature_vectors.shape[0],1))\n",
    "            concatenated_feature_vector = numpy.concatenate((feature_vectors,temp), axis=1)\n",
    "            \n",
    "#             print(concatenated_feature_vector.shape)\n",
    "#             print(fbank_vectors.shape)\n",
    "            \n",
    "            # append file's data to dataset\n",
    "            dataset = numpy.concatenate((dataset, concatenated_feature_vector), axis=0)\n",
    "            \n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "/home/rohan/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "# from numpy import genfromtxt\n",
    "my_data = get_feature_vectors(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 53)\n"
     ]
    }
   ],
   "source": [
    "# numpy.set_printoptions(threshold=numpy.nan)\n",
    "# print(my_data)\n",
    "print(my_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = numpy.copy(my_data[:, no_of_columns:])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 52)\n",
      "(1, 52)\n",
      "(1, 52)\n",
      "(3200, 52)\n"
     ]
    }
   ],
   "source": [
    "X = numpy.copy(my_data[:, :no_of_columns])\n",
    "print(X.shape)\n",
    "mean = X.mean(0, keepdims=True)\n",
    "\n",
    "print(mean.shape)\n",
    "std_deviation = numpy.std(X, axis=0, keepdims=True)\n",
    "print(std_deviation.shape)\n",
    "\n",
    "normalized_X = (X - mean) / std_deviation\n",
    "print(normalized_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras import utils as np_utils\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "one_hot_labels = np_utils.to_categorical(Y, num_classes=10)\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # MultiLayer Perceptron\n",
    "    model = Sequential()\n",
    "\n",
    "    # 3000 0.6 1500 0.6 -> 57% acc\n",
    "    # 2560 0.7 1280 0.7 -> 60% acc\n",
    "    # 2560 0.7 1600 0.7 -> 51% acc\n",
    "    # 2560 0.6 1600 0.7 -> 49%\n",
    "    # 2560 0.7 1280 -   -> 50\n",
    "    # 3000 0.7 1280 0.7 -> 54% acc\n",
    "    # 2560 0.7 1280 0.8 -> 45% acc\n",
    "\n",
    "    model.add(Dense(3000, activation='tanh', input_dim=no_of_columns))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(normalized_X, one_hot_labels, epochs=10, batch_size=32)\n",
    "    \n",
    "    return model\n",
    "# score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    test_model = get_feature_vectors(\"test\")\n",
    "    print(test_model.shape)\n",
    "\n",
    "    test_X = numpy.copy(test_model[:, :no_of_columns])\n",
    "#     print(test_X.shape)\n",
    "\n",
    "    normalized_test_X = (test_X - mean) / std_deviation\n",
    "#     print(normalized_test_X.shape)\n",
    "\n",
    "    test_Y = numpy.copy(test_model[:, no_of_columns:])\n",
    "#     print(test_Y.shape)\n",
    "    test_labels = np_utils.to_categorical(test_Y, num_classes=10)\n",
    "\n",
    "#     print(model.test_on_batch(test_X, test_labels, sample_weight=None))\n",
    "#     print(model.metrics_names)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    b = [sum(predictions[current: current+40]) for current in range(0, len(predictions), 40)]\n",
    "    predicted_Y = []\n",
    "    for row in b:\n",
    "        predicted_Y.append(row.argmax(axis=0))\n",
    "    \n",
    "    for t, p in zip(test_Y[::40].T[0], predicted_Y):\n",
    "        print (int(t), p)\n",
    "    \n",
    "    diff = predicted_Y - test_Y[::40].T[0]\n",
    "    correct = sum(x == 0 for x in diff)\n",
    "    total = len(predicted_Y)\n",
    "    percent = correct/total * 100\n",
    "    print(str(correct) + \" / \" + str(total) + \" = \" + str(percent))\n",
    "    \n",
    "    loss = str(numpy.sum(numpy.abs(diff)))\n",
    "    print(\"Loss = \" + loss)\n",
    "    \n",
    "    return correct, percent, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 2s 770us/step - loss: 1.2949 - acc: 0.5494\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 3s 883us/step - loss: 0.6396 - acc: 0.7659 0s - loss: 0.6433 - acc: 0.76\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 3s 824us/step - loss: 0.5386 - acc: 0.7987\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 3s 960us/step - loss: 0.5081 - acc: 0.8063\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 3s 1000us/step - loss: 0.4550 - acc: 0.8294\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 3s 952us/step - loss: 0.4305 - acc: 0.8441\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 4s 1ms/step - loss: 0.3968 - acc: 0.8578\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 3s 1ms/step - loss: 0.3783 - acc: 0.8544\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 3s 958us/step - loss: 0.3768 - acc: 0.8697\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 4s 1ms/step - loss: 0.3507 - acc: 0.8722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "/home/rohan/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2280, 53)\n",
      "6 6\n",
      "2 7\n",
      "4 4\n",
      "9 7\n",
      "2 1\n",
      "3 4\n",
      "7 9\n",
      "3 3\n",
      "1 8\n",
      "1 1\n",
      "7 7\n",
      "6 6\n",
      "9 7\n",
      "1 8\n",
      "1 6\n",
      "3 4\n",
      "4 4\n",
      "1 1\n",
      "9 7\n",
      "4 4\n",
      "4 4\n",
      "2 1\n",
      "6 6\n",
      "2 1\n",
      "9 7\n",
      "7 3\n",
      "3 3\n",
      "7 3\n",
      "2 1\n",
      "6 6\n",
      "3 4\n",
      "6 6\n",
      "4 7\n",
      "8 8\n",
      "7 7\n",
      "7 7\n",
      "3 4\n",
      "7 3\n",
      "4 4\n",
      "1 6\n",
      "9 7\n",
      "8 8\n",
      "3 3\n",
      "6 6\n",
      "1 8\n",
      "4 4\n",
      "9 9\n",
      "7 3\n",
      "9 9\n",
      "1 1\n",
      "2 1\n",
      "3 4\n",
      "6 6\n",
      "6 6\n",
      "9 9\n",
      "8 8\n",
      "8 8\n",
      "30 / 57 = 52.6315789474\n",
      "Loss = 77.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 52.631578947368418, '77.0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train()\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def cnn_train():\n",
    "    \n",
    "    temp = normalized_X.reshape(normalized_X.shape[0], no_of_columns, 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    # 13 7 1 1 0.25 60 0.25 10 - 70%\n",
    "    model.add(Convolution1D(52, 13, activation='tanh', input_shape=(no_of_columns,1)))\n",
    "    model.add(Convolution1D(52, 7, activation='tanh'))\n",
    "    model.add(Convolution1D(13, 3, activation='tanh'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=(1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(temp, one_hot_labels, epochs=10, batch_size=32)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_cnn(model):\n",
    "    \n",
    "    test_model = get_feature_vectors(\"test\")\n",
    "#     print(test_model.shape)\n",
    "\n",
    "    test_X = numpy.copy(test_model[:, :no_of_columns])\n",
    "#     print(test_X.shape)\n",
    "\n",
    "    normalized_test_X = (test_X - mean) / std_deviation\n",
    "#     print(normalized_test_X.shape)\n",
    "\n",
    "    test_Y = numpy.copy(test_model[:, no_of_columns:])\n",
    "#     print(test_Y.shape)\n",
    "    test_labels = np_utils.to_categorical(test_Y, num_classes=10)\n",
    "    \n",
    "    test_X = test_X.reshape(test_X.shape[0], no_of_columns, 1)\n",
    "    normalized_test_X = normalized_test_X.reshape(normalized_test_X.shape[0], no_of_columns, 1)\n",
    "    \n",
    "    print(model.test_on_batch(test_X, test_labels, sample_weight=None))\n",
    "    print(model.metrics_names)\n",
    "    predictions = model.predict(test_X)\n",
    "\n",
    "    b = [sum(predictions[current: current+40]) for current in range(0, len(predictions), 40)]\n",
    "    predicted_Y = []\n",
    "    for row in b:\n",
    "        predicted_Y.append(row.argmax(axis=0))\n",
    "\n",
    "    # print(predicted_Y)\n",
    "    # print(test_Y[::40].T)\n",
    "\n",
    "    for t, p in zip(test_Y[::40].T[0], predicted_Y):\n",
    "       print (int(t), p)\n",
    "\n",
    "    diff = predicted_Y - test_Y[::40].T[0]\n",
    "\n",
    "    numerator = sum(x == 0 for x in diff)\n",
    "    denominator = len(predicted_Y)\n",
    "\n",
    "    print(\"{} of {}\".format(numerator, denominator))\n",
    "\n",
    "    print(\"Accuracy: {}\".format(numerator/denominator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 1.0949 - acc: 0.6100\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.6151 - acc: 0.7619\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.5261 - acc: 0.8028\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.4500 - acc: 0.8344A: 1s - \n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.3715 - acc: 0.8625\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 6s 2ms/step - loss: 0.3286 - acc: 0.8803\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.2413 - acc: 0.9134\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.2113 - acc: 0.9194\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.1781 - acc: 0.9328A: 1s - loss: 0.178\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 7s 2ms/step - loss: 0.1551 - acc: 0.9459A: 6s - loss: 0. - ETA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "/home/rohan/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(2.7975258827209473, dtype=float32), array(0.47587719559669495, dtype=float32)]\n",
      "['loss', 'acc']\n",
      "6 6\n",
      "2 7\n",
      "4 4\n",
      "9 7\n",
      "2 1\n",
      "3 4\n",
      "7 9\n",
      "3 7\n",
      "1 1\n",
      "1 1\n",
      "7 7\n",
      "6 6\n",
      "9 9\n",
      "1 1\n",
      "1 6\n",
      "3 3\n",
      "4 4\n",
      "1 1\n",
      "9 7\n",
      "4 4\n",
      "4 4\n",
      "2 1\n",
      "6 6\n",
      "2 1\n",
      "9 7\n",
      "7 7\n",
      "3 3\n",
      "7 7\n",
      "2 1\n",
      "6 6\n",
      "3 3\n",
      "6 6\n",
      "4 4\n",
      "8 8\n",
      "7 7\n",
      "7 7\n",
      "3 3\n",
      "7 7\n",
      "4 4\n",
      "1 1\n",
      "9 9\n",
      "8 8\n",
      "3 3\n",
      "6 6\n",
      "1 1\n",
      "4 4\n",
      "9 9\n",
      "7 7\n",
      "9 9\n",
      "1 1\n",
      "2 1\n",
      "3 4\n",
      "6 6\n",
      "6 6\n",
      "9 9\n",
      "8 8\n",
      "8 8\n",
      "43 of 57\n",
      "Accuracy: 0.7543859649122807\n"
     ]
    }
   ],
   "source": [
    "cnn_model = cnn_train()\n",
    "test_cnn(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "/home/rohan/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(2.5421512126922607, dtype=float32), array(0.5074561238288879, dtype=float32)]\n",
      "['loss', 'acc']\n",
      "6 6\n",
      "2 1\n",
      "4 4\n",
      "9 9\n",
      "2 1\n",
      "3 4\n",
      "7 9\n",
      "3 3\n",
      "1 1\n",
      "1 1\n",
      "7 7\n",
      "6 6\n",
      "9 9\n",
      "1 1\n",
      "1 1\n",
      "3 3\n",
      "4 4\n",
      "1 1\n",
      "9 9\n",
      "4 4\n",
      "4 4\n",
      "2 1\n",
      "6 6\n",
      "2 1\n",
      "9 7\n",
      "7 3\n",
      "3 3\n",
      "7 7\n",
      "2 1\n",
      "6 6\n",
      "3 3\n",
      "6 6\n",
      "4 7\n",
      "8 8\n",
      "7 7\n",
      "7 3\n",
      "3 3\n",
      "7 7\n",
      "4 4\n",
      "1 1\n",
      "9 9\n",
      "8 8\n",
      "3 3\n",
      "6 6\n",
      "1 1\n",
      "4 4\n",
      "9 9\n",
      "7 3\n",
      "9 9\n",
      "1 1\n",
      "2 1\n",
      "3 4\n",
      "6 6\n",
      "6 6\n",
      "9 9\n",
      "8 8\n",
      "8 8\n",
      "43 of 57\n",
      "Accuracy: 0.7543859649122807\n"
     ]
    }
   ],
   "source": [
    "# test(model)\n",
    "test_cnn(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohan/anaconda3/lib/python3.6/site-packages/python_speech_features-0.6-py3.6.egg/python_speech_features/__init__.py'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import python_speech_features\n",
    "python_speech_features.__file__\n",
    "\n",
    "# print(predicted_Y)\n",
    "# print(test_Y[::40].T)\n",
    "\n",
    "# for t, p in zip(test_Y[::40].T[0], predicted_Y):\n",
    "#     print (int(t), p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# majority\n",
    "\n",
    "# argmax_pred = numpy.argmax(predictions, axis=1)\n",
    "# argmax_pred = argmax_pred.reshape((-1, 25))\n",
    "\n",
    "# from scipy.stats import mode\n",
    "# argmax_pred = mode(argmax_pred, axis=-1)[0]\n",
    "\n",
    "# # print(argmax_pred)\n",
    "# # print(test_Y)\n",
    "\n",
    "# for t, p in zip(test_Y[::40].T[0], argmax_pred):\n",
    "#     print (int(t), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def find_majority(k):\n",
    "#     myMap = {}\n",
    "#     maximum = ( '', 0 ) # (occurring element, occurrences)\n",
    "#     for n in k:\n",
    "#         if n in myMap: myMap[n] += 1\n",
    "#         else: myMap[n] = 1\n",
    "\n",
    "#         # Keep track of maximum on the go\n",
    "#         if myMap[n] > maximum[1]: maximum = (n,myMap[n])\n",
    "\n",
    "#     return maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
